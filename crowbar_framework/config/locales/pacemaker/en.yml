#
# Copyright 2011-2013, Dell
# Copyright 2013-2014, SUSE LINUX Products GmbH
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

en:
  nav:
    pacemaker: 'Pacemaker'
  api:
    pacemaker:
      ha_not_installed: 'HA add-on is not installed.'
      ha_not_configured: 'No Pacemaker cluster is configured.'
  barclamp:
    pacemaker:
      edit_attributes:
        drbd_header: 'DRBD'
        drbd:
          info: 'Using DRBD for replicated storage is an alternative to using shared storage for high availability of services like database and RabbitMQ. This requires the cluster to have two nodes only, as well as one dedicated disk on each cluster member.'
          enabled: 'Prepare cluster for DRBD'
        haproxy_header: 'HAProxy'
        haproxy:
          ssl_info:
            'The hostname for each virtual IP of HAProxy is generated by
            prefixing the name of the network to "%{vhostname}". For instance,
            the hostname of the admin virtual IP will be "admin.%{vhostname}".
            If using SSL for services that will be served behind HAProxy, then
            the SSL certificates will have to be valid for the hostname of the
            virtual IP for each network being used (in general, admin and
            public), and for the public name if defined.'
          public_name: 'Public name for public virtual IP'
          public_name_hint:
            'The public name is the hostname that will be used instead of the
            generated public name for the public virtual IP of HAProxy (when
            registering public endpoints, for instance). Any name specified
            here should already exist in the upstream DNS zones.'
        gui_header: 'Pacemaker GUI'
        corosync:
          password: 'Password for hacluster user in Hawk'
          transport: 'Transport for Communication'
          transports:
            udp: 'Multicast (UDP)'
            udpu: 'Unicast (UDPU)'
          require_clean_for_autostart_wrapper: 'Do not start corosync on boot after fencing'
          require_clean_for_autostart_values:
            auto: 'Automatic'
            v_true: 'True'
            v_false: 'False'
          require_clean_for_autostart_hint:
            'This setting can be used to avoid the STONITH deathmatch issue for
            two-nodes clusters, or a fencing loop. The corosync service will
            not start on boot on a node when that node was not properly shut
            down or rebooted; you will have to manually start it after having
            fixed the issue. "Automatic" means that this setting will be set to
            "true" for two-nodes cluster, and to "false" otherwise.'
          loading_text: 'Loading rings...'
          listheader: 'Corosync Rings'
          parameters: 'Ring %{index} Parameters'
          addheader: 'Add new Corosync Ring'
          rings:
            index:
              network: 'Network'
              mcast_addr: 'Multicast Address'
              mcast_port: 'Multicast Port'
        clone_stateless_services: 'Manage stateless active/active services with Pacemaker'
        clone_stateless_services_hint:
          'Stateless active/active services can be managed by Pacemaker, or can
          run as standard services. If they are managed by Pacemaker, then
          Pacemaker will automatically restart them on failures and will setup
          cluster-wide constraints to ensure correct ordering when starting
          services. If they run as standard services, then the complexity of
          the configuration is reduced and this limits the causes for fencing
          in case of failures.'
        crm:
          no_quorum_policy: 'Policy when cluster does not have quorum'
          no_quorum_policy_hint_html: 'Refer to the <a href="http://clusterlabs.org/doc/en-US/Pacemaker/1.1-crmsh/html/Pacemaker_Explained/_available_cluster_options.html">pacemaker documentation</a> for a description of each value.'
        stonith_header: 'STONITH'
        stonith_modes:
          manual: 'Configured manually'
          ipmi_barclamp: 'Configured with IPMI data from IPMI barclamp'
          sbd: 'Configured with STONITH Block Devices (SBD)'
          shared: 'Configured with one shared resource for the whole cluster'
          per_node: 'Configured with one resource per node'
          libvirt: 'Configured for nodes running in libvirt'
        stonith:
          mode: 'Configuration mode for STONITH'
          no_nodes: 'No nodes have been assigned a pacemaker role.'
          sbd:
            info_html: 'Manual configuration is required for SBD: before applying the proposal, you will have to ensure that the devices are available and initialized for SBD. You will also need to manually setup a watchdog if not all nodes use the same watchdog kernel module. Refer to the <a href="http://www.linux-ha.org/wiki/SBD_Fencing">Linux HA documentation</a> for details.'
            name: 'Node name'
            watchdog_module: 'Kernel module for watchdog'
            watchdog_module_hint: 'Leave the watchdog module attribute empty if the nodes need different watchdog modules.'
            devices: 'Block devices for node'
            devices_hint: 'Multiple devices can be specified in the comma-separated list. It is advised to use a stable path for devices (with /dev/disk/by-id/, for instance).'
          shared:
            agent: 'Fencing agent'
            params: 'Parameters for agent'
          per_node:
            agent: 'Fencing agent'
            name: 'Node name'
            params: 'Parameters for agent'
          libvirt:
            dev_only: 'The libvirt STONITH configuration is not supported, it should be used for development or testing purposes only!'
            hypervisor_ip: 'IP address of hypervisor'
            hypervisor_ip_hint: 'Note that libvirt on your host needs to be configured to listen on TCP, with no TLS and no authentication. The firewall should also be configured to allow communication from the virtual machines.'
        notifications_header: 'Mail Notifications'
        notifications:
          smtp:
            enabled: 'Enable Mail Notifications'
            server: 'SMTP Server'
            server_hint: 'Note that the SMTP server needs to be reachable from the nodes.'
            prefix: 'Subject Prefix'
            from: 'Sender Address'
            to: 'Recipient Address'
      validation:
        missing_sbd_device: 'Missing SBD devices for node %{member}.'
        empty_sbd_device: 'Some SBD devices for node %{node_name} are empty.'
        missing_sbd_for_node: 'Missing SBD devices for node %{node_name}.'
        node_no_cluster_member: 'SBD devices present for node %{node_name}, while this node is not a member of the cluster.'
        same_number_of_devices: 'All nodes must share the same number of SBD devices (with possibly different paths).'
        missing_fencing_agent: 'Missing fencing agent for shared setup.'
        missing_fencing_agent_params: 'Missing fencing agent parameters for shared setup.'
        shared_params_no_hostlist: 'The hostlist for fencing agent parameters for shared setup must not included as it will be automatically computed.'
        missing_fencing_agent_per_node: 'Missing fencing agent for per-node setup.'
        node_missing_fencing_params: 'Missing fencing agent parameters for node %{member}'
        fencing_agent_no_cluster: 'Fencing agent parameters present for node %{node_name}, while this node is not a member of the cluster.'
        automatic_ipmi_setup: 'Automatic IPMI setup not available for node %{member}.'
        hypervisor_ip: 'Hypervisor IP \"%{hypervisor_ip}\" is invalid.'
        libvirt: 'Node  %{member} does not seem to be running in libvirt.'
        stonith_mode: 'Unknown STONITH mode: %{stonith_mode}.'
        hawk_server: 'Node %{name} has the hawk-server role but not the pacemaker-cluster-member role.'
        smtp_server: 'Invalid SMTP server for mail notifications.'
        sender_address: 'Invalid sender address for mail notifications.'
        recipient_address: 'Invalid recipient address for mail notifications.'
        drbd: 'Setting up DRBD requires a cluster of two nodes.'
        ha_repo: 'The SLE HA repositories have not been setup.'
        transport_value: 'Invalid transport value: %{transport}.'
        ring_network_too_many: 'Too many rings specified. Only two rings are allowed.'
        ring_network_empty: 'A network must be specified for the %{ring_ordinal} corosync ring.'
        ring_network_notfound: 'Network "%{ring_network}" not found for the %{ring_ordinal} corosync ring.'
        ring_network_notunique: 'The network "%{ring_network}" has been specified more than once.'
        allocate_ip: 'Failed to allocate address for node "%{node}" on network "%{network}" (Error %{retcode}).'
        mcast_addr_empty_free: 'A multicast address for ring %{ring_index} is required. Multicast address %{free_addr} is available.'
        mcast_addr_used_free: 'The specified multicast address %{used_addr} for ring %{ring_index} is in use but %{free_addr} is available.'
        mcast_addr_used_none_avail: 'All multicast addresses are in use, including %{used_addr}.'
        mcast_addr_none_avail: 'All multicast addresses are in use.'
        quorum_policy: 'Invalid no-quorum-policy value: %{no_quorum_policy}.'
        platform: 'All nodes in proposal must have the same platform.'
        pacemaker_proposal: 'Nodes cannot be part of multiple Pacemaker proposals, but %{other_member} is already part of proposal \"%{p_name}\".'
